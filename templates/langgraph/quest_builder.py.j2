"""
LangGraph Quest Builder for {{ goal_id }}

Auto-generated by GoalGen
Builds the complete LangGraph workflow
"""

import json
import os
from typing import Dict, Any
from pathlib import Path

from langgraph.graph import StateGraph, END

from .state_schema import {{ goal_id | pascal_case }}State
from .checkpointer_adapter import create_checkpointer
from .agents import (
    {% for agent_name in agents.keys() %}
    {{ agent_name }}_node,
    {% endfor %}
)

from frmk.utils.logging import get_logger

logger = get_logger("quest_builder")


def load_goal_config(config_path: str = None) -> Dict[str, Any]:
    """
    Load goal configuration from spec

    Args:
        config_path: Path to goal_spec.json (optional)
                     Falls back to GOAL_SPEC_PATH env var or default location
    """

    if config_path is None:
        config_path = os.getenv("GOAL_SPEC_PATH")

    if config_path is None:
        config_path = Path(__file__).parent.parent / "config" / "goal_spec.json"
    else:
        config_path = Path(config_path)

    if not config_path.exists():
        raise FileNotFoundError(f"Goal spec not found: {config_path}")

    logger.debug(f"Loading goal config from: {config_path}")
    with open(config_path) as f:
        return json.load(f)


def build_graph(goal_config: Dict[str, Any] = None) -> StateGraph:
    """
    Build LangGraph workflow for {{ goal_id }}

    Args:
        goal_config: Goal configuration dict (optional, will load from file if not provided)

    StateManager automatically:
    - Tracks conversations in Azure Conversation API
    - Logs metrics to AI Foundry
    - Persists state to {{ checkpointing_backend }}
    """

    logger.info("Building LangGraph workflow for {{ goal_id }}")

    # Load config if not provided
    if goal_config is None:
        goal_config = load_goal_config()

    # Create graph
    graph = StateGraph({{ goal_id | pascal_case }}State)

    # Add agent nodes
    {% for agent_name in agents.keys() %}
    graph.add_node("{{ agent_name }}", {{ agent_name }}_node)
    {% endfor %}

    # Add special nodes
    graph.add_node("ask_missing", ask_missing_node)

    # Wire edges based on topology
    {% if topology.pattern == 'supervisor' %}
    # Supervisor pattern
    graph.set_entry_point("{{ topology.supervisor }}")

    # Conditional routing from supervisor
    graph.add_conditional_edges(
        "{{ topology.supervisor }}",
        route_from_supervisor,
        {
            {% for worker in topology.workers %}
            "{{ worker }}": "{{ worker }}",
            {% endfor %}
            "ask_missing": "ask_missing",
            "END": END
        }
    )

    # Workers return to supervisor
    {% for worker in topology.workers %}
    graph.add_edge("{{ worker }}", "{{ topology.supervisor }}")
    {% endfor %}

    # Ask missing returns to supervisor
    graph.add_edge("ask_missing", "{{ topology.supervisor }}")

    {% elif topology.pattern == 'sequential' %}
    # Sequential pattern
    {% for i in range(tasks | length) %}
    {% if i == 0 %}
    graph.set_entry_point("{{ tasks[i].id }}")
    {% else %}
    graph.add_edge("{{ tasks[i-1].id }}", "{{ tasks[i].id }}")
    {% endif %}
    {% endfor %}

    graph.add_edge("{{ tasks[-1].id }}", END)

    {% else %}
    # Default: set entry point
    graph.set_entry_point("{{ agents.keys() | list | first }}")
    {% endif %}

    # Create checkpointer with StateManager
    checkpointer = create_checkpointer(goal_config)

    # Compile graph
    compiled_graph = graph.compile(checkpointer=checkpointer)

    logger.info("LangGraph workflow compiled successfully")

    return compiled_graph


{% if topology.pattern == 'supervisor' %}
def route_from_supervisor(state: {{ goal_id | pascal_case }}State) -> str:
    """Route from supervisor based on state"""

    next_node = state.get("next", "END")
    logger.debug(f"Supervisor routing to: {next_node}")
    return next_node
{% endif %}


async def ask_missing_node(state: {{ goal_id | pascal_case }}State) -> Dict[str, Any]:
    """Special node for asking missing information"""

    from langchain_core.messages import AIMessage

    missing_field = state.get("missing_field", "unknown")
    prompt = f"I need some additional information: {missing_field.replace('_', ' ')}. Could you please provide this?"

    return {
        "messages": state["messages"] + [AIMessage(content=prompt)],
        "next": "END"
    }


# Export compiled graph (uses default config loading)
# For custom config, call build_graph(goal_config) directly
graph = build_graph()
